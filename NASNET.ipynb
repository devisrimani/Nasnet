{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10c9e4fc-7d90-47c3-a465-df6076b2ebc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import NASNetLarge\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11627f2d-0ccd-493e-b14c-7e0c07279592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to train and test directories\n",
    "train_dir = r\"C:\\Desktop\\STUDY\\PROJECTS\\Project sem VI\\archive (1)\\Skin cancer ISIC The International Skin Imaging Collaboration\\Train\"\n",
    "test_dir = r\"C:\\Desktop\\STUDY\\PROJECTS\\Project sem VI\\archive (1)\\Skin cancer ISIC The International Skin Imaging Collaboration\\Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "939d12a1-6539-403b-8c80-143b0ec2ea19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Desktop\\STUDY\\PROJECTS\\Project sem VI\\archi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Desktop\\STUDY\\PROJECTS\\Project sem VI\\archi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Desktop\\STUDY\\PROJECTS\\Project sem VI\\archi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Desktop\\STUDY\\PROJECTS\\Project sem VI\\archi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Desktop\\STUDY\\PROJECTS\\Project sem VI\\archi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2352</th>\n",
       "      <td>C:\\Desktop\\STUDY\\PROJECTS\\Project sem VI\\archi...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2353</th>\n",
       "      <td>C:\\Desktop\\STUDY\\PROJECTS\\Project sem VI\\archi...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2354</th>\n",
       "      <td>C:\\Desktop\\STUDY\\PROJECTS\\Project sem VI\\archi...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2355</th>\n",
       "      <td>C:\\Desktop\\STUDY\\PROJECTS\\Project sem VI\\archi...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2356</th>\n",
       "      <td>C:\\Desktop\\STUDY\\PROJECTS\\Project sem VI\\archi...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2357 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             image_path label\n",
       "0     C:\\Desktop\\STUDY\\PROJECTS\\Project sem VI\\archi...     0\n",
       "1     C:\\Desktop\\STUDY\\PROJECTS\\Project sem VI\\archi...     0\n",
       "2     C:\\Desktop\\STUDY\\PROJECTS\\Project sem VI\\archi...     0\n",
       "3     C:\\Desktop\\STUDY\\PROJECTS\\Project sem VI\\archi...     0\n",
       "4     C:\\Desktop\\STUDY\\PROJECTS\\Project sem VI\\archi...     0\n",
       "...                                                 ...   ...\n",
       "2352  C:\\Desktop\\STUDY\\PROJECTS\\Project sem VI\\archi...     7\n",
       "2353  C:\\Desktop\\STUDY\\PROJECTS\\Project sem VI\\archi...     7\n",
       "2354  C:\\Desktop\\STUDY\\PROJECTS\\Project sem VI\\archi...     8\n",
       "2355  C:\\Desktop\\STUDY\\PROJECTS\\Project sem VI\\archi...     8\n",
       "2356  C:\\Desktop\\STUDY\\PROJECTS\\Project sem VI\\archi...     8\n",
       "\n",
       "[2357 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame(columns=['image_path', 'label'])\n",
    "test_df = pd.DataFrame(columns=['image_path', 'label'])\n",
    "\n",
    "for label, directory in enumerate(os.listdir(train_dir)):\n",
    "    for filename in os.listdir(os.path.join(train_dir, directory)):\n",
    "        image_path = os.path.join(train_dir, directory, filename)\n",
    "        train_df = pd.concat([train_df, pd.DataFrame({'image_path': [image_path], 'label': [label]})], ignore_index=True)\n",
    "\n",
    "for label, directory in enumerate(os.listdir(test_dir)):\n",
    "    for filename in os.listdir(os.path.join(test_dir, directory)):\n",
    "        image_path = os.path.join(test_dir, directory, filename)\n",
    "        test_df = pd.concat([test_df, pd.DataFrame({'image_path': [image_path], 'label': [label]})], ignore_index=True)\n",
    "\n",
    "\n",
    "df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "del test_df,train_df\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1bdfcdc-266e-4cbd-ab2b-b37deb6dfd26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'actinic keratosis',\n",
       " 1: 'basal cell carcinoma',\n",
       " 2: 'dermatofibroma',\n",
       " 3: 'melanoma',\n",
       " 4: 'nevus',\n",
       " 5: 'pigmented benign keratosis',\n",
       " 6: 'seborrheic keratosis',\n",
       " 7: 'squamous cell carcinoma',\n",
       " 8: 'vascular lesion'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get list of directories in train_dir\n",
    "labels = os.listdir(train_dir)\n",
    "\n",
    "# Create label_map dictionary\n",
    "label_map = {i: label for i, label in enumerate(labels)}\n",
    "num_classes=len(label_map)\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a3e5169-e494-491b-8764-a63123614b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DEVADHARSHINI K\\AppData\\Local\\Temp\\ipykernel_18892\\3886418994.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(\"label\").apply(lambda x: x.head(max_images_per_class)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "max_images_per_class = 2500\n",
    "\n",
    "# Group by label column and take first max_images_per_class rows for each group\n",
    "df = df.groupby(\"label\").apply(lambda x: x.head(max_images_per_class)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f3a2186-24f4-42bf-897c-90dec43aa559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Allow gpu usage\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth = True\n",
    "except Exception as ex:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53d03d7b-bc58-44a6-a40f-98a4b3e1accf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "# Get the number of CPU cores available\n",
    "max_workers = multiprocessing.cpu_count()\n",
    "max_workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "803f711f-33fd-4ad2-a802-b4079d842054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Desktop\\STUDY\\PROJECTS\\Project sem VI\\archi...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[[139, 79, 87], [138, 77, 84], [128, 63, 65],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Desktop\\STUDY\\PROJECTS\\Project sem VI\\archi...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[[114, 85, 85], [96, 66, 60], [86, 64, 69], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Desktop\\STUDY\\PROJECTS\\Project sem VI\\archi...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[[166, 120, 116], [170, 126, 122], [175, 132,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Desktop\\STUDY\\PROJECTS\\Project sem VI\\archi...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[[168, 91, 91], [179, 103, 102], [185, 112, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Desktop\\STUDY\\PROJECTS\\Project sem VI\\archi...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[[206, 155, 156], [206, 156, 157], [211, 164,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path label  \\\n",
       "0  C:\\Desktop\\STUDY\\PROJECTS\\Project sem VI\\archi...     0   \n",
       "1  C:\\Desktop\\STUDY\\PROJECTS\\Project sem VI\\archi...     0   \n",
       "2  C:\\Desktop\\STUDY\\PROJECTS\\Project sem VI\\archi...     0   \n",
       "3  C:\\Desktop\\STUDY\\PROJECTS\\Project sem VI\\archi...     0   \n",
       "4  C:\\Desktop\\STUDY\\PROJECTS\\Project sem VI\\archi...     0   \n",
       "\n",
       "                                               image  \n",
       "0  [[[139, 79, 87], [138, 77, 84], [128, 63, 65],...  \n",
       "1  [[[114, 85, 85], [96, 66, 60], [86, 64, 69], [...  \n",
       "2  [[[166, 120, 116], [170, 126, 122], [175, 132,...  \n",
       "3  [[[168, 91, 91], [179, 103, 102], [185, 112, 1...  \n",
       "4  [[[206, 155, 156], [206, 156, 157], [211, 164,...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "from PIL import Image\n",
    "# Define a function to resize image arrays\n",
    "def resize_image_array(image_path):\n",
    "    return np.asarray(Image.open(image_path).resize((100,75)))\n",
    "\n",
    "# Use concurrent.futures to parallelize the resizing process\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    # Use executor.map to apply the function to each image path in the DataFrame\n",
    "    image_arrays = list(executor.map(resize_image_array, df['image_path'].tolist()))\n",
    "\n",
    "# Add the resized image arrays to the DataFrame\n",
    "df['image'] = image_arrays\n",
    "del image_arrays\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6bc5b25-f5a0-4ea0-a279-43a98baa4f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Summary\n",
      "------------------------------------------------------------\n",
      "Class Label     Class Name                     Count     \n",
      "------------------------------------------------------------\n",
      "0               actinic keratosis              130       \n",
      "1               basal cell carcinoma           392       \n",
      "2               dermatofibroma                 111       \n",
      "3               melanoma                       454       \n",
      "4               nevus                          373       \n",
      "5               pigmented benign keratosis     478       \n",
      "6               seborrheic keratosis           80        \n",
      "7               squamous cell carcinoma        197       \n",
      "8               vascular lesion                142       \n",
      "------------------------------------------------------------\n",
      "Total                                         2357      \n"
     ]
    }
   ],
   "source": [
    "class_counts = df['label'].value_counts().sort_index()\n",
    "\n",
    "# Print the number of images in each class\n",
    "print(\"Dataset Summary\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Class Label':<15} {'Class Name':<30} {'Count':<10}\")\n",
    "print(\"-\" * 60)\n",
    "for class_label, class_name in label_map.items():\n",
    "    count = class_counts[class_label]\n",
    "    print(f\"{class_label:<15} {class_name:<30} {count:<10}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Total':<45} {sum(class_counts):<10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07941518-5e8a-4bd6-a0cf-5ec6327d4f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create an ImageDataGenerator object with the desired transformations\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "687c79bd-84b2-4035-8c6b-11088df78cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2357,) (2357, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "features = df.drop(columns=['label','image_path'],axis=1)\n",
    "target = df['label']\n",
    "print(target.shape,features.shape)\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.20,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a226bb2-4665-4cb1-b217-7821de7bcaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray(x_train['image'].tolist())\n",
    "x_test = np.asarray(x_test['image'].tolist())\n",
    "\n",
    "x_train_mean = np.mean(x_train)\n",
    "x_train_std = np.std(x_train)\n",
    "x_test_mean = np.mean(x_test)\n",
    "x_test_std = np.std(x_test)\n",
    "\n",
    "x_train = (x_train - x_train_mean)/x_train_std\n",
    "x_test = (x_test - x_test_mean)/x_test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08cde01d-f22e-4acb-9110-bc40f0caabcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train,num_classes = num_classes)\n",
    "y_test = to_categorical(y_test,num_classes = num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51caef27-3ea6-4292-9f52-07de9da66129",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size = 0.20,shuffle=True)\n",
    "# Reshape image in 3 dimensions (height = 75px, width = 100px , canal = 3)\n",
    "x_train = x_train.reshape(x_train.shape[0], *(75, 100, 3))\n",
    "x_test = x_test.reshape(x_test.shape[0], *(75, 100, 3))\n",
    "x_validate = x_validate.reshape(x_validate.shape[0], *(75, 100, 3))\n",
    "y_train = y_train.astype(int)\n",
    "y_validate = y_validate.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ef55f85-867c-4567-bbd3-51bf6a51e99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 331, 331 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c65b9d95-fef0-40ed-ac3e-67d52fe097a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to train and test directories\n",
    "train_dir = r\"C:\\Desktop\\STUDY\\PROJECTS\\Project sem VI\\archive (1)\\Skin cancer ISIC The International Skin Imaging Collaboration\\Train\"\n",
    "test_dir = r\"C:\\Desktop\\STUDY\\PROJECTS\\Project sem VI\\archive (1)\\Skin cancer ISIC The International Skin Imaging Collaboration\\Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6b9033b-3c5a-46d9-826c-02d9a27d7374",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(os.listdir(train_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90e75abc-b877-49fd-a4df-19cf606cfdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5da62453-4716-455b-9418-8b8e107ff2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation for training images\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0833b43f-b069-4c0e-a7ce-a5057ddc43b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation for test images (only rescaling)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8511ac09-9d1d-4fa7-b893-2bf5848f2bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2239 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "# Generate batches of augmented data for training and validation\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0890819c-3b5c-447d-be1f-33a34a3e730a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 118 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd1992f2-26ef-417f-8e15-d89cb6f8c959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NASNetLarge model without classification layers\n",
    "base_model = NASNetLarge(include_top=False, input_shape=(img_width, img_height, 3), weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d39ff40-2d78-481c-9457-a60179dd0f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add custom classification layers on top of NASNetLarge\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01d87a1c-fce4-4e4f-b34b-f8c371bbfa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine base model with custom layers\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a271690-6280-47ec-92af-35e632fdb067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the base model layers (only train custom classification layers)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78ed9cdb-86db-440b-91d2-c9fd9c65ea75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with specified learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "723e7a5d-5370-4d83-8028-5e2d9c992cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DEVADHARSHINI K\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m757s\u001b[0m 11s/step - accuracy: 0.3115 - loss: 1.8708 - val_accuracy: 0.2708 - val_loss: 2.1354\n",
      "Epoch 2/3\n",
      "\u001b[1m 1/69\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:45\u001b[0m 10s/step - accuracy: 0.3125 - loss: 1.8255"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DEVADHARSHINI K\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 118ms/step - accuracy: 0.3125 - loss: 1.8255 - val_accuracy: 0.3636 - val_loss: 1.8901\n",
      "Epoch 3/3\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m751s\u001b[0m 11s/step - accuracy: 0.4914 - loss: 1.4720 - val_accuracy: 0.3229 - val_loss: 1.9389\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2540b2ace00>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=3,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e1e4aaf5-f70f-482e-bef9-2214437ec62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 9s/step - accuracy: 0.3189 - loss: 1.9443\n",
      "Test: accuracy = 0.305085  ;  loss = 1.946879\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_generator, verbose=1)\n",
    "print(\"Test: accuracy = %f  ;  loss = %f\" % (accuracy, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed5f2962-592e-4cb0-8df1-5cdb56a41cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "Predicted class: dermatofibroma\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "sample_img_path = r\"C:\\Desktop\\STUDY\\PROJECTS\\Project sem VI\\archive (1)\\Skin cancer ISIC The International Skin Imaging Collaboration\\Train\\dermatofibroma\\ISIC_0025223.jpg\"\n",
    "img = image.load_img(sample_img_path, target_size=(img_width, img_height))\n",
    "\n",
    "# Preprocess the image\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array /= 255.\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(img_array)\n",
    "predicted_class = np.argmax(predictions)\n",
    "\n",
    "# Get the class label\n",
    "class_labels = list(train_generator.class_indices.keys())\n",
    "predicted_label = class_labels[predicted_class]\n",
    "\n",
    "print(\"Predicted class:\", predicted_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b94f302a-2091-477f-9688-bc951fe9a734",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('skin_disease_classification_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
